import{_ as n,o as a,c as l,a as p}from"./app.f9cf8683.js";const F=JSON.parse('{"title":"站点如何防止爬虫？","description":"","frontmatter":{},"headers":[],"relativePath":"fragment/爬虫.md","lastUpdated":1740908463000}'),o={name:"fragment/爬虫.md"};function e(r,s,t,c,i,B){return a(),l("div",null,s[0]||(s[0]=[p(`<h1 id="站点如何防止爬虫" tabindex="-1">站点如何防止爬虫？ <a class="header-anchor" href="#站点如何防止爬虫" aria-hidden="true">#</a></h1><ol><li><p><strong>修改 robots.txt</strong><br><code>robots.txt</code> 文件告知遵守该协议的爬虫应该爬取哪些页面，哪些不应该爬取。通常在站点根目录下创建该文件。<br><strong>实现方案：</strong></p><ul><li>在站点的根目录下创建 <code>robots.txt</code> 文件。</li><li>使用 <code>Disallow</code> 指令禁止爬虫访问特定路径，示例：<div class="language- line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang"></span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#abb2bf;">User-agent: *</span></span>
<span class="line"><span style="color:#abb2bf;">Disallow: /private/</span></span>
<span class="line"><span style="color:#abb2bf;">Disallow: /secret/</span></span>
<span class="line"><span style="color:#abb2bf;"></span></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#b392f0;">User-agent: *</span></span>
<span class="line"><span style="color:#b392f0;">Disallow: /private/</span></span>
<span class="line"><span style="color:#b392f0;">Disallow: /secret/</span></span>
<span class="line"><span style="color:#b392f0;"></span></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div></li><li><code>robots.txt</code> 只能限制遵守该协议的爬虫，恶意爬虫可以忽视此文件。</li></ul></li><li><p><strong>使用 CAPTCHA</strong><br> 对于表单提交、登录等关键操作使用 CAPTCHA 进行验证，防止自动化脚本提交。<br><strong>实现方案：</strong></p><ul><li>在登录、注册、评论等表单中集成 CAPTCHA（例如 Google reCAPTCHA）。</li><li>验证用户是否为机器人（通过图形识别或行为分析），通过成功验证后才允许提交。</li><li>常见的 CAPTCHA 服务有 reCAPTCHA、hCaptcha 等。</li></ul></li><li><p><strong>检查用户代理字符串</strong><br> 通过检查请求头中的 <code>User-Agent</code> 字段来识别并屏蔽一些已知的爬虫。<br><strong>实现方案：</strong></p><ul><li>在服务器端检查请求的 <code>User-Agent</code> 字符串，确定是否为常见的爬虫（如 Googlebot, Bingbot 等）。</li><li>示例：<div class="language-javascript line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#C678DD;">const</span><span style="color:#ABB2BF;"> </span><span style="color:#E5C07B;">userAgent</span><span style="color:#ABB2BF;"> </span><span style="color:#56B6C2;">=</span><span style="color:#ABB2BF;"> </span><span style="color:#E5C07B;">request</span><span style="color:#ABB2BF;">.</span><span style="color:#E06C75;">headers</span><span style="color:#ABB2BF;">[</span><span style="color:#98C379;">&quot;user-agent&quot;</span><span style="color:#ABB2BF;">];</span></span>
<span class="line"><span style="color:#C678DD;">if</span><span style="color:#ABB2BF;"> (</span><span style="color:#E06C75;">/bot</span><span style="color:#ABB2BF;">|</span><span style="color:#E06C75;">crawl</span><span style="color:#ABB2BF;">|</span><span style="color:#E06C75;">slurp</span><span style="color:#ABB2BF;">|</span><span style="color:#E06C75;">spider/</span><span style="color:#C678DD;">i</span><span style="color:#ABB2BF;">.</span><span style="color:#61AFEF;">test</span><span style="color:#ABB2BF;">(</span><span style="color:#E06C75;">userAgent</span><span style="color:#ABB2BF;">)) {</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#E5C07B;">response</span><span style="color:#ABB2BF;">.</span><span style="color:#61AFEF;">status</span><span style="color:#ABB2BF;">(</span><span style="color:#D19A66;">403</span><span style="color:#ABB2BF;">).</span><span style="color:#61AFEF;">send</span><span style="color:#ABB2BF;">(</span><span style="color:#98C379;">&quot;Forbidden&quot;</span><span style="color:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#ABB2BF;">}</span></span>
<span class="line"></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#F97583;">const</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">userAgent</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">request</span><span style="color:#B392F0;">.headers[</span><span style="color:#FFAB70;">&quot;user-agent&quot;</span><span style="color:#B392F0;">];</span></span>
<span class="line"><span style="color:#F97583;">if</span><span style="color:#B392F0;"> (</span><span style="color:#FFAB70;">/bot</span><span style="color:#F97583;">|</span><span style="color:#FFAB70;">crawl</span><span style="color:#F97583;">|</span><span style="color:#FFAB70;">slurp</span><span style="color:#F97583;">|</span><span style="color:#FFAB70;">spider/</span><span style="color:#F97583;">i</span><span style="color:#B392F0;">.test(userAgent)) {</span></span>
<span class="line"><span style="color:#B392F0;">  </span><span style="color:#79B8FF;">response</span><span style="color:#B392F0;">.status(</span><span style="color:#F8F8F8;">403</span><span style="color:#B392F0;">).send(</span><span style="color:#FFAB70;">&quot;Forbidden&quot;</span><span style="color:#B392F0;">);</span></span>
<span class="line"><span style="color:#B392F0;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li><li>注意：用户代理字符串易于伪造，因此此方法不够可靠。</li></ul></li><li><p><strong>分析流量行为</strong><br> 通过监控和分析访问者的行为模式，如访问频率、访问时长等，来识别非正常行为。<br><strong>实现方案：</strong></p><ul><li>使用日志分析工具（如 Google Analytics 或服务器端日志）监测访问频率、访问路径和停留时间。</li><li>如果某个 IP 短时间内请求过于频繁，超过常人行为，可以标记为潜在爬虫，并采取拦截措施。</li><li>设定阈值，超过请求次数限制的 IP 可以被临时封禁。</li></ul></li><li><p><strong>使用 Web 应用防火墙（WAF）</strong><br> WAF 可以有效地识别并阻止常见的爬虫和攻击行为。<br><strong>实现方案：</strong></p><ul><li>部署 WAF（例如 AWS WAF, Cloudflare WAF）来过滤掉来自恶意爬虫的请求。</li><li>配置规则来检测并阻止针对特定页面、IP 或请求频率的异常流量。</li><li>一些 WAF 提供机器人检测和阻止功能，能够自动识别常见的爬虫行为。</li></ul></li><li><p><strong>服务端渲染和动态 Token</strong><br> 通过服务端渲染和动态生成令牌，防止非浏览器工具获取页面内容。<br><strong>实现方案：</strong></p><ul><li>使用 JavaScript 服务端渲染（SSR）技术，在服务器端生成 HTML，并注入动态内容。</li><li>将页面关键内容如令牌或验证码动态插入到 HTML 中，而不是将静态内容直接嵌入页面。</li><li>每次请求时生成唯一的 token，爬虫无法获取正确的 token，防止内容被抓取。</li></ul></li><li><p><strong>添加额外的 HTTP 头</strong><br> 在每个请求中添加特定的 HTTP 头，这些头部信息通常是由 JavaScript 动态生成的，爬虫工具可能不会模拟这些行为。<br><strong>实现方案：</strong></p><ul><li>在站点响应头中加入自定义 HTTP 头（如 <code>X-Custom-Header</code>），并在请求中验证其值。</li><li>示例：<div class="language-javascript line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#7F848E;font-style:italic;">// 在服务器端验证请求头</span></span>
<span class="line"><span style="color:#C678DD;">if</span><span style="color:#ABB2BF;"> (</span><span style="color:#E5C07B;">request</span><span style="color:#ABB2BF;">.</span><span style="color:#E06C75;">headers</span><span style="color:#ABB2BF;">[</span><span style="color:#98C379;">&quot;X-Custom-Header&quot;</span><span style="color:#ABB2BF;">] </span><span style="color:#56B6C2;">!==</span><span style="color:#ABB2BF;"> </span><span style="color:#98C379;">&quot;expected_value&quot;</span><span style="color:#ABB2BF;">) {</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#C678DD;">return</span><span style="color:#ABB2BF;"> </span><span style="color:#E5C07B;">response</span><span style="color:#ABB2BF;">.</span><span style="color:#61AFEF;">status</span><span style="color:#ABB2BF;">(</span><span style="color:#D19A66;">403</span><span style="color:#ABB2BF;">).</span><span style="color:#61AFEF;">send</span><span style="color:#ABB2BF;">(</span><span style="color:#98C379;">&quot;Forbidden&quot;</span><span style="color:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#ABB2BF;">}</span></span>
<span class="line"></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#6B737C;">// 在服务器端验证请求头</span></span>
<span class="line"><span style="color:#F97583;">if</span><span style="color:#B392F0;"> (</span><span style="color:#79B8FF;">request</span><span style="color:#B392F0;">.headers[</span><span style="color:#FFAB70;">&quot;X-Custom-Header&quot;</span><span style="color:#B392F0;">] </span><span style="color:#F97583;">!==</span><span style="color:#B392F0;"> </span><span style="color:#FFAB70;">&quot;expected_value&quot;</span><span style="color:#B392F0;">) {</span></span>
<span class="line"><span style="color:#B392F0;">  </span><span style="color:#F97583;">return</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">response</span><span style="color:#B392F0;">.status(</span><span style="color:#F8F8F8;">403</span><span style="color:#B392F0;">).send(</span><span style="color:#FFAB70;">&quot;Forbidden&quot;</span><span style="color:#B392F0;">);</span></span>
<span class="line"><span style="color:#B392F0;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li><li>通过 JavaScript 动态添加这些头信息，爬虫通常无法正确模拟请求头。</li></ul></li><li><p><strong>IP 黑名单</strong><br> 如果发现某个 IP 地址表现出异常访问行为（如访问频繁、无效请求等），将其列入黑名单。<br><strong>实现方案：</strong></p><ul><li>监控访问日志，识别异常 IP（如请求频率过高的 IP）。</li><li>使用反向代理或防火墙工具（如 Nginx, HAProxy）拦截特定 IP 地址的访问。</li><li>示例：<div class="language-nginx line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#C678DD;">if</span><span style="color:#ABB2BF;"> ($</span><span style="color:#E06C75;">remote_addr</span><span style="color:#ABB2BF;"> = </span><span style="color:#98C379;">&quot;123.123.123.123&quot;</span><span style="color:#ABB2BF;">) {</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#C678DD;">return</span><span style="color:#ABB2BF;"> </span><span style="color:#D19A66;">403</span><span style="color:#ABB2BF;">;</span></span>
<span class="line"><span style="color:#ABB2BF;">}</span></span>
<span class="line"></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#F97583;">if</span><span style="color:#B392F0;"> ($remote_addr </span><span style="color:#F97583;">= </span><span style="color:#FFAB70;">&quot;123.123.123.123&quot;</span><span style="color:#B392F0;">) {</span></span>
<span class="line"><span style="color:#B392F0;">  </span><span style="color:#F97583;">return</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">403</span><span style="color:#B392F0;">;</span></span>
<span class="line"><span style="color:#B392F0;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br></div></div></li><li>这样可以有效阻止恶意爬虫继续访问网站。</li></ul></li><li><p><strong>限制访问速度</strong><br> 对访问进行速率限制，禁止过于频繁的请求。<br><strong>实现方案：</strong></p><ul><li>设置速率限制（例如每分钟请求次数），对于超过阈值的请求，返回 429 错误（Too Many Requests）。</li><li>使用工具如 Nginx 限制请求速率：<div class="language-nginx line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">nginx</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#C678DD;">limit_req_zone </span><span style="color:#ABB2BF;">$</span><span style="color:#E06C75;">binary_remote_addr</span><span style="color:#ABB2BF;"> zone=one:10m rate=1r/s;</span></span>
<span class="line"><span style="color:#C678DD;">limit_req </span><span style="color:#ABB2BF;">zone=one burst=5;</span></span>
<span class="line"></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#F97583;">limit_req_zone </span><span style="color:#B392F0;">$binary_remote_addr zone=one:10m rate=1r/s;</span></span>
<span class="line"><span style="color:#F97583;">limit_req </span><span style="color:#B392F0;">zone=one burst=5;</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br></div></div></li><li>这能有效限制爬虫对页面的快速抓取。</li></ul></li><li><p><strong>API 限流</strong><br> 针对开放的 API，设置访问频率限制，防止恶意爬虫大量访问接口。<br><strong>实现方案：</strong></p><ul><li>在服务器端实现 API 限速（如每个用户每分钟请求次数限制）。</li><li>使用 Redis 或数据库记录每个用户的请求时间，并根据请求次数进行限制。</li><li>示例：<div class="language-javascript line-numbers-mode"><button title="Copy Code" class="copy"></button><span class="lang">javascript</span><pre class="shiki one-dark-pro vp-code-dark"><code><span class="line"><span style="color:#C678DD;">const</span><span style="color:#ABB2BF;"> </span><span style="color:#E5C07B;">rateLimiter</span><span style="color:#ABB2BF;"> </span><span style="color:#56B6C2;">=</span><span style="color:#ABB2BF;"> </span><span style="color:#C678DD;">new</span><span style="color:#ABB2BF;"> </span><span style="color:#61AFEF;">RateLimiter</span><span style="color:#ABB2BF;">({ </span><span style="color:#E06C75;">max</span><span style="color:#ABB2BF;">: </span><span style="color:#D19A66;">100</span><span style="color:#ABB2BF;">, </span><span style="color:#E06C75;">window</span><span style="color:#ABB2BF;">: </span><span style="color:#D19A66;">60</span><span style="color:#ABB2BF;"> });</span></span>
<span class="line"><span style="color:#C678DD;">if</span><span style="color:#ABB2BF;"> (</span><span style="color:#56B6C2;">!</span><span style="color:#E5C07B;">rateLimiter</span><span style="color:#ABB2BF;">.</span><span style="color:#61AFEF;">allowRequest</span><span style="color:#ABB2BF;">(</span><span style="color:#E06C75;">userId</span><span style="color:#ABB2BF;">)) {</span></span>
<span class="line"><span style="color:#ABB2BF;">  </span><span style="color:#E5C07B;">response</span><span style="color:#ABB2BF;">.</span><span style="color:#61AFEF;">status</span><span style="color:#ABB2BF;">(</span><span style="color:#D19A66;">429</span><span style="color:#ABB2BF;">).</span><span style="color:#61AFEF;">send</span><span style="color:#ABB2BF;">(</span><span style="color:#98C379;">&quot;Too many requests&quot;</span><span style="color:#ABB2BF;">);</span></span>
<span class="line"><span style="color:#ABB2BF;">}</span></span>
<span class="line"></span></code></pre><pre class="shiki min-dark vp-code-light"><code><span class="line"><span style="color:#F97583;">const</span><span style="color:#B392F0;"> </span><span style="color:#79B8FF;">rateLimiter</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">=</span><span style="color:#B392F0;"> </span><span style="color:#F97583;">new</span><span style="color:#B392F0;"> RateLimiter({ max</span><span style="color:#F97583;">:</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">100</span><span style="color:#BBBBBB;">,</span><span style="color:#B392F0;"> window</span><span style="color:#F97583;">:</span><span style="color:#B392F0;"> </span><span style="color:#F8F8F8;">60</span><span style="color:#B392F0;"> });</span></span>
<span class="line"><span style="color:#F97583;">if</span><span style="color:#B392F0;"> (</span><span style="color:#F97583;">!</span><span style="color:#79B8FF;">rateLimiter</span><span style="color:#B392F0;">.allowRequest(userId)) {</span></span>
<span class="line"><span style="color:#B392F0;">  </span><span style="color:#79B8FF;">response</span><span style="color:#B392F0;">.status(</span><span style="color:#F8F8F8;">429</span><span style="color:#B392F0;">).send(</span><span style="color:#FFAB70;">&quot;Too many requests&quot;</span><span style="color:#B392F0;">);</span></span>
<span class="line"><span style="color:#B392F0;">}</span></span>
<span class="line"></span></code></pre><div class="line-numbers-wrapper" aria-hidden="true"><span class="line-number">1</span><br><span class="line-number">2</span><br><span class="line-number">3</span><br><span class="line-number">4</span><br></div></div></li></ul></li><li><p><strong>使用 HTTPS</strong><br> HTTPS 加密协议不仅能提升安全性，还能增加爬虫抓取的难度。<br><strong>实现方案：</strong></p><ul><li>在站点上启用 HTTPS，通过 SSL/TLS 加密所有通信。</li><li>确保所有的请求都通过 HTTPS 访问，避免 HTTP 中间人攻击。</li><li>使用免费的 SSL 证书（如 Let’s Encrypt）或者付费证书来保障网站的安全性。</li></ul></li><li><p><strong>更改网站结构和内容</strong><br> 定期更新网站的 URL 结构、内容排版等，迫使爬虫更新其抓取策略。<br><strong>实现方案：</strong></p><ul><li>定期重构网站的目录结构和 URL 路径，改变页面的布局和元素的 DOM 结构。</li><li>将一些敏感内容使用动态加载的方式呈现，爬虫难以抓取。</li></ul></li></ol><p>通过这些方法，可以有效增加爬虫抓取网站内容的难度，保护站点免受恶意抓取。</p>`,3)]))}const d=n(o,[["render",e]]);export{F as __pageData,d as default};
